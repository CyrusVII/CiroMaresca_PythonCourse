{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37cba4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Carica il dataset Iris come DataFrame\n",
    "iris = load_iris(as_frame=True)\n",
    "# Seleziona solo le feature \"petal length\" e \"petal width\"\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "# Crea il target binario: True se è \"Iris-setosa\", altrimenti False\n",
    "y = (iris.target == 0)\n",
    "# Inizializza il modello Perceptron con un seed fisso per la riproducibilità\n",
    "per_clf = Perceptron(random_state=42)\n",
    "# Allena il Perceptron sui dati selezionati\n",
    "per_clf.fit(X, y)\n",
    "# Nuovi esempi da classificare (lunghezza e larghezza del petalo)\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "# Predice se i nuovi fiori sono \"Iris-setosa\" (True) o no (False)\n",
    "y_pred = per_clf.predict(X_new)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ceefba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (Validation): 0.505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# --- Caricamento del dataset California Housing ---\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data            # Feature (es. numero di stanze, popolazione, ecc.)\n",
    "y = housing.target          # Target: valore medio delle case in una zona\n",
    "\n",
    "# --- Suddivisione dei dati in training, validation e test ---\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)  # 75% train+valid, 25% test\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)  # 56.25% train, 18.75% valid\n",
    "\n",
    "# --- Definizione del modello MLP ---\n",
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],  # Tre hidden layer da 50 neuroni ciascuno\n",
    "    activation='relu',                # Funzione di attivazione ReLU\n",
    "    solver='adam',                    # Ottimizzatore Adam\n",
    "    alpha=0.0001,                     # Termina di regolarizzazione L2 (per evitare overfitting)\n",
    "    max_iter=500,                     # Iterazioni massime\n",
    "    random_state=42                   # Seed per riproducibilità\n",
    ")\n",
    "\n",
    "# --- Creazione della pipeline ---\n",
    "# Include uno StandardScaler per normalizzare le feature (molto importante per MLP)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "\n",
    "# --- Addestramento del modello ---\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --- Predizione e valutazione sul validation set ---\n",
    "y_pred = pipeline.predict(X_valid)                                  # Predizioni sul set di validazione\n",
    "rmse = sqrt(mean_squared_error(y_valid, y_pred))          # Calcolo della Root Mean Squared Error\n",
    "\n",
    "# --- Stampa dell'errore ---\n",
    "print(f\"Root Mean Squared Error (Validation): {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fc55f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf  # Importa TensorFlow, una libreria per costruire e addestrare reti neurali\n",
    "\n",
    "# --- Caricamento del dataset Fashion MNIST ---\n",
    "# Fashion MNIST è un dataset con immagini 28x28 pixel in scala di grigi di vestiti (10 categorie)\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Carica i dati e li divide in set di training e test\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "# --- Suddivisione in sottoinsiemi: training e validation ---\n",
    "# Prende tutti i dati tranne gli ultimi 5000 per addestrare (training)\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "\n",
    "# Gli ultimi 5000 dati vengono usati per la validazione (validation)\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "# --- Normalizzazione dei pixel ---\n",
    "# I pixel vanno da 0 a 255: qui li convertiamo in valori da 0.0 a 1.0 (per aiutare l'apprendimento)\n",
    "X_train = X_train / 255.0\n",
    "X_valid = X_valid / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# --- Etichette delle classi ---\n",
    "# Questo array associa il numero di ogni etichetta (0-9) al nome del capo d'abbigliamento\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "# --- Visualizzazione della prima etichetta del training set ---\n",
    "# Questa riga mostra il nome del capo corrispondente alla prima immagine del training set\n",
    "class_names[y_train[0]]\n",
    "\n",
    "#per vedere l immagine associata\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap=\"gray\")\n",
    "plt.title(class_names[y_train[0]])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e87a13b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf  # Importa TensorFlow\n",
    "\n",
    "tf.random.set_seed(42)  # Imposta un seme per la casualità (utile per ripetere gli stessi risultati)\n",
    "\n",
    "# --- Definizione del modello neurale ---\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28)),         # Input: immagini 28x28 (come nel dataset Fashion MNIST)\n",
    "    \n",
    "    tf.keras.layers.Flatten(),              # Appiattisce l'immagine 28x28 in un vettore di 784 valori (28*28)\n",
    "    \n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),  # Primo strato pienamente connesso (dense) con 300 neuroni e ReLU\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),  # Secondo strato denso con 100 neuroni e ReLU\n",
    "    \n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\") # Output: 10 neuroni (uno per ogni classe), softmax per probabilità\n",
    "])\n",
    "\n",
    "# --- Mostra un riepilogo del modello ---\n",
    "model.summary()  # Stampa la struttura del modello: numero di parametri, forma degli strati, ecc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.2166 - val_accuracy: 0.8750 - val_loss: 0.3493\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2129 - val_accuracy: 0.8760 - val_loss: 0.3492\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2090 - val_accuracy: 0.8760 - val_loss: 0.3478\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2055 - val_accuracy: 0.8770 - val_loss: 0.3479\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2020 - val_accuracy: 0.8780 - val_loss: 0.3487\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.1984 - val_accuracy: 0.8780 - val_loss: 0.3480\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9331 - loss: 0.1951 - val_accuracy: 0.8790 - val_loss: 0.3496\n",
      "Epoch 8/30\n",
      "\u001b[1m 334/1719\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.1838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SGD\n\u001b[32m      3\u001b[39m model.compile(\n\u001b[32m      4\u001b[39m loss=\u001b[33m\"\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m optimizer=SGD(learning_rate=\u001b[32m0.01\u001b[39m),\n\u001b[32m      6\u001b[39m metrics=[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ciro\\Desktop\\CorsoPython\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Importa l'ottimizzatore SGD (Stochastic Gradient Descent) da Keras\n",
    "from tensorflow import SGD\n",
    "\n",
    "# Compila il modello specificando:\n",
    "# - La funzione di loss (usata per classificazione multi-classe con etichette intere)\n",
    "# - L'ottimizzatore (SGD con learning rate 0.01)\n",
    "# - Le metriche da monitorare (accuracy = accuratezza della classificazione)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=SGD(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Allena il modello:\n",
    "# - Usa il training set (X_train, y_train)\n",
    "# - Per 30 epoche\n",
    "# - Valida le prestazioni su X_valid e y_valid ad ogni epoca\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
